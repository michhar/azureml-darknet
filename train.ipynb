{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/ml-frameworks/fastai/train-with-custom-docker/fastai-with-custom-docker.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model using a custom Docker image and Darknet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, learn how to use a custom Docker image when training models with Azure Machine Learning and leverage the Darknet framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "1. Install of Python 3 in development environment (e.g. local or DSVM).  Use `pip install requirements_local.txt` to install necessary packages on the command line in a Python environment (virtual or conda environment).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core import Dataset\n",
    "from azureml.core import Environment\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core import ScriptRunConfig\n",
    "from azureml.core import Experiment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "import os\n",
    "from uuid import uuid4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize a workspace\n",
    "The Azure Machine Learning workspace is the top-level resource for the service. It provides you with a centralized place to work with all the artifacts you create. In the Python SDK, you can access the workspace artifacts by creating a `workspace` object.\n",
    "\n",
    "Create a workspace object from the `config.json` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload dataset to default Data Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default data store (backend is Blob Storage) for this Workspace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the data folder where the `data` folder is structured as:\n",
    "```\n",
    "    data/\n",
    "        img/\n",
    "            image1.jpg\n",
    "            image1.txt\n",
    "            image2.jpg\n",
    "            image2.txt\n",
    "            ...\n",
    "        train.txt\n",
    "        valid.txt\n",
    "        obj.data\n",
    "        obj.names\n",
    "```\n",
    "\n",
    "Note, `train.txt` looks similiar to the following snippet (image path is from `data` root) and `valid.txt` follows the same pattern:\n",
    "```\n",
    "data/img/image1.jpg\n",
    "data/img/image2.jpg\n",
    "...\n",
    "```\n",
    "\n",
    "Note, it is recommended that 5-10% of all images should go in to the `valid.txt` image list.  There should not be overlap between the two lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore = ws.get_default_datastore()\n",
    "datastore.upload(src_dir='./data_products',\n",
    "                 target_path='data',\n",
    "                 overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an Azure ML Dataset.  A Dataset can reference single or multiple files in your datastores or public urls. The files can be of any format. Dataset provides you with the ability to download or mount the files to your compute. By creating a dataset, you create a reference to the data source location. The data remains in its existing location, so no extra storage cost is incurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize file dataset \n",
    "ds_paths = [(datastore, 'data/')]\n",
    "dataset = Dataset.File.from_files(path=ds_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare scripts\n",
    "Create a directory titled `darknet_scripts` for training script any any testing scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('darknet_scripts', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup test script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then run the cell below to create the a script to test the setup in the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%%writefile darknet_scripts/test_setup.py\n",
    "\"\"\"\n",
    "Azure ML test setup script for Darknet object detection experiment\n",
    "\"\"\"\n",
    "import os\n",
    "import requests\n",
    "import subprocess\n",
    "import shutil\n",
    "import argparse\n",
    "\n",
    "\n",
    "# Test greeting\n",
    "def greeting():\n",
    "    print(\"Welcome to darknet container!\")\n",
    "greeting()\n",
    "\n",
    "os.makedirs('./outputs', exist_ok=True)\n",
    "\n",
    "# Arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data-folder', type=str,\n",
    "                    dest='data_folder', help='data folder')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Look at data folder\n",
    "print('Data folder is at:', args.data_folder)\n",
    "print('List all files: ', os.listdir(args.data_folder))\n",
    "\n",
    "fulldatapath = os.path.join(args.data_folder, \"data\")\n",
    "\n",
    "print(\"Contents of data folder: \")\n",
    "os.system(\"ls data\")\n",
    "\n",
    "print(\"Getting the test image...\")\n",
    "# Get a test image\n",
    "url = \"https://raw.githubusercontent.com/AlexeyAB/darknet/master/data/giraffe.jpg\"\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    with open(\"giraffe.jpg\", \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "# Make coco.data file\n",
    "coco_data = \"\"\"\n",
    "classes= 80\n",
    "train  = train.txt\n",
    "valid  = val.txt\n",
    "names = coco.names\n",
    "backup = backup/\n",
    "eval=coco\n",
    "\"\"\"\n",
    "print(\"Making coco.data\")\n",
    "with open(\"coco.data\", \"w\") as f:\n",
    "    f.write(coco_data)\n",
    "\n",
    "print(\"Getting coco.names...\")\n",
    "# Get the names file\n",
    "url = \"https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/coco.names\"\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    with open(\"coco.names\", \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "print(\"Getting the weights file, yolov4.weights...\")\n",
    "# Get the weights file\n",
    "url = \"https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights\"\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    with open(\"yolov4.weights\", \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "print(\"Getting the config file...\")\n",
    "# Get the config file\n",
    "url = \"https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov4.cfg\"\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    with open(\"yolov4.cfg\", \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "# What is our current working directory?\n",
    "print(\"Current working directory: {}\".format(os.getcwd()))\n",
    "print(\"Contents of directory: \")\n",
    "os.system(\"ls\")\n",
    "\n",
    "# Predict with darknet\n",
    "print(\"Running darknet detector test!\")\n",
    "os.system(\"darknet detector test coco.data yolov4.cfg yolov4.weights -thresh 0.25 giraffe.jpg -ext_output\")\n",
    "os.system(\"ls\")\n",
    "\n",
    "if os.path.exists(\"predictions.jpg\"):\n",
    "    shutil.copyfile(\"predictions.jpg\", \"outputs/predictions.jpg\")\n",
    "if os.path.exists(\"predictions.png\"):\n",
    "    shutil.copyfile(\"predictions.png\", \"outputs/predictions.png\")\n",
    "\n",
    "\n",
    "print(\"Return value: {}\".format(retval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train script\n",
    "\n",
    "This is the training script.  It need not be modified as it utilizes some of the variables above as arguments, however feel free to improve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile darknet_scripts/train.py\n",
    "\"\"\"\n",
    "Azure ML train script for Darknet object detection experiment\n",
    "\"\"\"\n",
    "import os\n",
    "import requests\n",
    "import subprocess\n",
    "import shutil\n",
    "import argparse\n",
    "\n",
    "from azureml.core.run import Run\n",
    "from azureml.core.model import Model\n",
    "\n",
    "\n",
    "# Azure ML run to log metrics etc.\n",
    "run = Run.get_context()\n",
    "\n",
    "# Fill in number of classes\n",
    "num_classes = 3\n",
    "\n",
    "# Fill in with a list of anchor boxes\n",
    "anchors = \"42,98, 53,120, 58,137, 76,181, 109,162, 131,261\"\n",
    "\n",
    "# Test greeting\n",
    "def greeting():\n",
    "    print(\"Welcome to darknet container!\")\n",
    "greeting()\n",
    "\n",
    "os.makedirs('./outputs', exist_ok=True)\n",
    "\n",
    "# Arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data-folder', type=str,\n",
    "                    dest='data_folder', help='data folder')\n",
    "parser.add_argument('--lr', type=float, default=0.001,\n",
    "                    dest='lr', help='learning rate')\n",
    "parser.add_argument('--bs', type=int, default=4,\n",
    "                    dest='bs', help='minibatch size')\n",
    "parser.add_argument('--epochs', type=int, default=4,\n",
    "                    dest='epochs', help='number of epochs')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# ========================== Get data ==========================\n",
    "\n",
    "# Look at data folder\n",
    "print('Data folder is at:', args.data_folder)\n",
    "print('List all files: ', os.listdir(args.data_folder))\n",
    "\n",
    "fulldatapath = args.data_folder\n",
    "\n",
    "# ========================== Create or download necessary files ==========================\n",
    "    \n",
    "# Get the pre-trained weights file\n",
    "print(\"Getting the pre-trained weights file, yolov4-tiny.conv.29...\")\n",
    "url = \"https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.conv.29\"\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    with open(\"yolov4-tiny.conv.29\", \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "print(\"Creating the config file...\")\n",
    "# Get the config file\n",
    "url = \"https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov4-tiny.cfg\"\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    with open(\"yolov4-tiny.cfg\", \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "with open(\"yolov4-tiny.cfg\", \"r\") as f:\n",
    "    config_content = f.read()\n",
    "\n",
    "# Replace LR\n",
    "config_content = config_content.replace(\"learning_rate=0.00261\", \"learning_rate={}\".format(args.lr))\n",
    "# Replace number of filters in CN layer before yolo layer\n",
    "num_filters = (num_classes+5)*3\n",
    "config_content = config_content.replace(\"filters=255\", \"filters={}\".format(num_filters))\n",
    "# Replace number of classes\n",
    "config_content = config_content.replace(\"classes=80\", \"classes={}\".format(num_classes))\n",
    "# Replace batch size\n",
    "config_content = config_content.replace(\"batch=64\", \"batch={}\".format(args.bs))\n",
    "# Replace max batches/epochs and learning rate stepping epochs\n",
    "config_content = config_content.replace(\"max_batches = 2000200\", \"max_batches={}\".format(args.epochs))\n",
    "config_content = config_content.replace(\"steps=1600000,1800000\", \n",
    "                                        \"steps={},{}\".format(int(0.8*args.epochs), \n",
    "                                                             int(0.9*args.epochs)))\n",
    "# Replace anchors\n",
    "config_content = config_content.replace(\"10,14,  23,27,  37,58,  81,82,  135,169,  344,319\",\n",
    "                                       anchors)\n",
    "\n",
    "with open(\"yolov4-tiny-custom.cfg\", \"w\") as f:\n",
    "    f.write(config_content)\n",
    "if os.path.exists(\"yolov4-tiny-custom.cfg\"):\n",
    "    shutil.copyfile(\"yolov4-tiny-custom.cfg\", \"./outputs/yolov4-tiny-custom.cfg\")\n",
    "\n",
    "# What is our current working directory?\n",
    "print(\"Current working directory: {}\".format(os.getcwd()))\n",
    "print(\"Contents of directory: \")\n",
    "os.system(\"ls\")\n",
    "\n",
    "# ========================== Train model ==========================\n",
    "\n",
    "# Predict with darknet\n",
    "print(\"Running darknet training experiment for {} epochs!\".format(args.epochs))\n",
    "\n",
    "result = subprocess.run(['darknet', \n",
    "                         'detector',\n",
    "                         'train',\n",
    "                         'data/obj.data',\n",
    "                         'yolov4-tiny-custom.cfg', \n",
    "                         'yolov4-tiny.conv.29',\n",
    "                         '-map',\n",
    "                         '-dont_show',\n",
    "                         '-clear'], \n",
    "                        stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
    "\n",
    "os.system(\"ls\")\n",
    "\n",
    "mAP = \"\"\n",
    "# Capture mAP of final model (read from log file)\n",
    "result = result.split(\"\\n\")\n",
    "for line in result:\n",
    "    # This is what darknet outputs at end\n",
    "    if \"mean average precision (mAP@0.50)\" in line:\n",
    "        mAP = float(line[-8:].replace(\" % \", \"\"))\n",
    "        # Log to Azure ML workspace\n",
    "        run.log('mAP0.5_all', mAP)\n",
    "\n",
    "        \n",
    "# ========================== Register model - TBD ==========================\n",
    "\n",
    "# # Get class names as string\n",
    "# with open(\"./data/obj.names\", \"r\") as f:\n",
    "#     class_names = f.read().replace(\"\\n\", \"_\").replace(\" \", \"\").strip()\n",
    "\n",
    "# model = run.register_model(model_name='darknet-yolov4-tiny',\n",
    "#                            tags={\"mAP0.5_all\": mAP,\n",
    "#                                  \"classes\": class_names,\n",
    "#                                  \"learning_rate\": args.lr,\n",
    "#                                  \"batch_size\": args.bs,\n",
    "#                                  \"format\": \"darknet\"},\n",
    "#                            model_path=\"./outputs/yolov4-tiny-custom_final.weights\")\n",
    "\n",
    "\n",
    "# ========================== Small test - optional ==========================\n",
    "\n",
    "with open(\"data/valid.txt\", \"r\") as f:\n",
    "    validtxt = f.readlines()\n",
    "# Pick first image\n",
    "testimg = validtxt[0].strip()\n",
    "\n",
    "# Predict with darknet\n",
    "print(\"Running darknet detector test!\")\n",
    "os.system(\"darknet detector test data/obj.data yolov4-tiny-custom.cfg ./outputs/yolov4-tiny-custom_final.weights -thresh 0.25 {} -ext_output\".format(testimg))\n",
    "os.system(\"ls\")\n",
    "\n",
    "if os.path.exists(\"predictions.jpg\"):\n",
    "    shutil.copyfile(\"predictions.jpg\", \"./outputs/predictions.jpg\")\n",
    "\n",
    "# ========================== Convert model to onnx - TBD ==========================\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define your environment\n",
    "Create an environment object and enable Docker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darknet_env = Environment(\"darknet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to use a custom Dockerfile. Use this approach if you need to install non-Python packages as dependencies and remember to set the base image to None. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This specified base image supports the darknet framework which allows for object detection deep learning capabilities. For more information, see the [darknet GitHub repo](https://github.com/AlexeyAB/darknet). \n",
    "\n",
    "When you are using your custom Docker image, you might already have your Python environment properly set up. In that case, set the `user_managed_dependencies` flag to True in order to leverage your custom image's built-in python environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darknet_env.docker.base_image = None\n",
    "darknet_env.docker.base_dockerfile = \"./Dockerfile\"\n",
    "darknet_env.python.user_managed_dependencies = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create or attach existing AmlCompute\n",
    "You will need to create a [compute target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) for training your model. In this tutorial, you create `AmlCompute` as your training compute resource.\n",
    "\n",
    "**Creation of AmlCompute takes approximately 5 minutes.** If the AmlCompute with that name is already in your workspace this code will skip the creation process.\n",
    "\n",
    "As with other Azure services, there are limits on certain resources (e.g. AmlCompute) associated with the Azure Machine Learning service. Please read [this article](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-manage-quotas) on the default limits and how to request more quota."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a name for your cluster\n",
    "cluster_name = \"gpu-cluster\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target.')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6',\n",
    "                                                           max_nodes=4)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "    compute_target.wait_for_completion(show_output=True)\n",
    "\n",
    "# use get_status() to get a detailed status for the current AmlCompute\n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a ScriptRunConfig and submit for training\n",
    "This ScriptRunConfig will configure your job for execution on the desired compute target.  Here we are looping over a list of hyperparameters.  Note, the concurrency will be limited by the number of compute nodes in our compute target.\n",
    "\n",
    "When a training run is submitted using a ScriptRunConfig object, the submit method returns an object of type ScriptRun. The returned ScriptRun object gives you programmatic access to information about the training run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "hyperparams = {\"learning_rate\": [0.0005, 0.001],\n",
    "               \"batch_size\": [4, 6]}\n",
    "epochs = 3000\n",
    "\n",
    "# Iterate over hyperparameters\n",
    "for lr in hyperparams[\"learning_rate\"]:\n",
    "    for bs in hyperparams[\"batch_size\"]:\n",
    "    \n",
    "        script_args = ['--data-folder', \n",
    "                       dataset.as_named_input('data').as_mount('data'),\n",
    "                       '--lr', lr,\n",
    "                       '--bs', bs,\n",
    "                       '--epochs', epochs]\n",
    "\n",
    "        darknet_config = ScriptRunConfig(source_directory='darknet_scripts',\n",
    "                                        script='train.py',\n",
    "                                        arguments=script_args,\n",
    "                                        compute_target=compute_target,\n",
    "                                        environment=darknet_env)\n",
    "\n",
    "        run = Experiment(ws,'darknet-custom-image-hyper').submit(darknet_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "sagopal"
   }
  ],
  "category": "training",
  "compute": [
   "AML Compute"
  ],
  "datasets": [
   "Oxford IIIT Pet"
  ],
  "deployment": [
   "None"
  ],
  "exclude_from_index": false,
  "framework": [
   "Pytorch"
  ],
  "friendly_name": "Train a model with a custom Docker image",
  "index_order": 1,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "tags": [
   "None"
  ],
  "task": "Train with custom Docker image"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
